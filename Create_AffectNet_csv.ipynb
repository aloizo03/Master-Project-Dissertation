{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b94dacb0",
   "metadata": {},
   "source": [
    "# Script description\n",
    "This script is to create for the AffectNet dataset the csv for the training-testing data (in a single file) and the validation data which contains the image path and the emotion label.\n",
    "</br>\n",
    "Therefore, this script creates and the balance dataset based on the label.csv and the annotation file of test_outputs which has been created with the FairFace annotation tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f7157b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c1e955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_affectNet_csv(dataset_path='Dataset\\input', sub_paths=['train_set', 'val_set'], filenames=['labels.csv', 'val_labels.csv']):\n",
    "    \"\"\"\n",
    "    This function taking the dataset batch and the file name of CSV file which are gona create for validation data as one file\n",
    "    and an other one for the rest of data which will be used for training and testing\n",
    "    :param dataset_path: str, the dir where the affectnet folder dataset is contain (without have the affectnet)\n",
    "    :subs_paths: list, a list with the name of the folder for train and validation\n",
    "    :filenames: list, the filenames for each CSV file\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    dir_path = os.getcwd()\n",
    "    path_dataset_dir = os.path.join(dir_path, dataset_path)\n",
    "    path_dataset_dir = os.path.join(path_dataset_dir, 'affectnet')\n",
    "    image_filename_lst = []\n",
    "    label_lst = []\n",
    "    # from id to emotion class\n",
    "    from_id_to_emotion =  {0:'neutral', 1:'happy', 2:'sad', 3:'surprise', 4:'fear', 5:'disgust', 6:'anger', 7: 'contempt'}\n",
    "    for path, output in zip(sub_paths, filenames):\n",
    "        image_filename_lst = []\n",
    "        label_lst = []\n",
    "        \n",
    "        # have the path of the images and the anotations\n",
    "        path_dataset = os.path.join(path_dataset_dir, path)\n",
    "        path_dataset_images = os.path.join(path_dataset, 'images')\n",
    "        path_dataset_annotations = os.path.join(path_dataset, 'annotations')\n",
    "        arr = os.listdir(path_dataset_images)\n",
    "        # for all the paths read the images filename\n",
    "        for pth in arr:\n",
    "            filename_without_ext = os.path.splitext(pth)[0]\n",
    "            aro_filename = f'{filename_without_ext}_aro.npy'\n",
    "            exp_filename = f'{filename_without_ext}_exp.npy'\n",
    "            lnd_filename = f'{filename_without_ext}_lnd.npy'\n",
    "            val_filename = f'{filename_without_ext}_val.npy'\n",
    "            \n",
    "            filename = os.path.join(path_dataset_annotations, exp_filename)            \n",
    "            image_exp = np.load(filename)\n",
    "            \n",
    "            filename = os.path.join(path_dataset_annotations, lnd_filename)\n",
    "            image_lnd = np.load(filename)\n",
    "            \n",
    "            filename = os.path.join(path_dataset_annotations, val_filename)\n",
    "            image_val = np.load(filename)\n",
    "            \n",
    "            filename = os.path.join(path_dataset_annotations, aro_filename)\n",
    "            image_aro = np.load(filename)\n",
    "            \n",
    "            img_filename = os.path.join(path, 'images')\n",
    "            img_filename = os.path.join(img_filename, pth)\n",
    "            image_filename_lst.append(img_filename)\n",
    "            \n",
    "            label_lst.append(from_id_to_emotion[int(image_exp)])\n",
    "            \n",
    "        data = {'pth': image_filename_lst,\n",
    "                'label': label_lst}\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        csv_dir = os.path.join(path_dataset_dir, output)\n",
    "        df.to_csv(csv_dir, index=False)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392dc464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_balance_affect_Net_csv(dataset_dir='Dataset/input/affectnet', labels_csv='labels.csv', annotations_csv='test_outputs.csv'):\n",
    "    \"\"\"\n",
    "    This function created the balance datsaet in terms of the domain group of four races and the emotion classes\n",
    "    :param dataset_dir: str, the directory of the AffectNet dataset\n",
    "    :labels_csv: str, the filename of the labels and the image path of the affectNet dataset\n",
    "    :annotations_csv: str, the filename of the demographic group annotations\n",
    "    :return: pandas.Dataframe, the baalnce dataset image paths and emotion labels\n",
    "    \"\"\"\n",
    "    dir_path = os.getcwd()\n",
    "    path_dataset_dir = os.path.join(dir_path, dataset_dir)\n",
    "    path_sens_features = os.path.join(path_dataset_dir, annotations_csv)\n",
    "    path_csv_labels = os.path.join(path_dataset_dir, labels_csv)\n",
    "    \n",
    "    csv_sf = pd.read_csv(path_sens_features)\n",
    "    csv_labels = pd.read_csv(path_csv_labels)\n",
    "    df = pd.merge(csv_sf, csv_labels, on=\"pth\")\n",
    "    \n",
    "    # Read the labels and put it in a list\n",
    "    label_values = df['label'].values.tolist()\n",
    "    emotion_classes = list(set(df['label'].values.tolist()))\n",
    "    emotion_labels_count = [label_values.count(emotion) for emotion in emotion_classes]\n",
    "    \n",
    "    # Have the lower amount of a dataset\n",
    "    index_min = min(enumerate(emotion_labels_count), key=itemgetter(1))[0] \n",
    "    min_emotion = emotion_classes[index_min]\n",
    "    \n",
    "    balance_dataframe = df.loc[df['label'] == min_emotion]\n",
    "    min_emotions_values = emotion_labels_count[index_min]\n",
    "    \n",
    "    emotion_classes.remove(min_emotion)\n",
    "    race4 = ['Black', 'White', 'Indian', 'Asian']\n",
    "    equal_value = int(min_emotions_values/len(race4))\n",
    "    for emotion in emotion_classes:\n",
    "        df_emotion = df.loc[df['label'] == emotion]\n",
    "        # for each emotion class his four races is balance as add the same percentage for each sensitive feature group\n",
    "        for race in race4:\n",
    "            df_emotion_per_race = df_emotion[df_emotion['race4'] == race]\n",
    "            df_emotion_per_race = df_emotion_per_race.iloc[:equal_value]\n",
    "            balance_dataframe = pd.concat([balance_dataframe, df_emotion_per_race])\n",
    "\n",
    "    df_labels = balance_dataframe[['pth', 'label']]\n",
    "    df_race_annotations = balance_dataframe[['pth', 'race', 'race4', 'gender', 'age', 'race_scores_fair', 'race_scores_fair_4', 'gender_scores_fair', 'age_scores_fair']]\n",
    "    \n",
    "    balance_dataset_dir = os.path.join(path_dataset_dir, 'balance_dataset_labels.csv')\n",
    "    df_labels.to_csv(balance_dataset_dir, index=False)\n",
    "    \n",
    "    balance_dataset_dir = os.path.join(path_dataset_dir, 'balance_dataset_annotations.csv')\n",
    "    df_race_annotations.to_csv(balance_dataset_dir, index=False)\n",
    "    return df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74947986",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_balance_affect_Net_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "780a65d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pth</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train_set\\images\\100012.jpg</td>\n",
       "      <td>contempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>train_set\\images\\100047.jpg</td>\n",
       "      <td>contempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>train_set\\images\\10015.jpg</td>\n",
       "      <td>contempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>train_set\\images\\100251.jpg</td>\n",
       "      <td>contempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>train_set\\images\\100368.jpg</td>\n",
       "      <td>contempt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205484</th>\n",
       "      <td>train_set\\images\\366930.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205642</th>\n",
       "      <td>train_set\\images\\367132.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205841</th>\n",
       "      <td>train_set\\images\\367397.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206181</th>\n",
       "      <td>train_set\\images\\36785.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206275</th>\n",
       "      <td>train_set\\images\\367977.jpg</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26183 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                pth     label\n",
       "12      train_set\\images\\100012.jpg  contempt\n",
       "42      train_set\\images\\100047.jpg  contempt\n",
       "120      train_set\\images\\10015.jpg  contempt\n",
       "201     train_set\\images\\100251.jpg  contempt\n",
       "299     train_set\\images\\100368.jpg  contempt\n",
       "...                             ...       ...\n",
       "205484  train_set\\images\\366930.jpg     anger\n",
       "205642  train_set\\images\\367132.jpg     anger\n",
       "205841  train_set\\images\\367397.jpg     anger\n",
       "206181   train_set\\images\\36785.jpg     anger\n",
       "206275  train_set\\images\\367977.jpg     anger\n",
       "\n",
       "[26183 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4006989",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_affectNet_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224d109f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40bee2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
